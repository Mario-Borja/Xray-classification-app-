# -----------------------------------------------------------------------------
# Archivo: pages/page_4.py
# Contenido: Exploraci√≥n del Dataset de Rayos X y An√°lisis de Desbalance
# -----------------------------------------------------------------------------
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from PIL import Image
import random

# --- Verificaci√≥n de Autenticaci√≥n ---
if 'logged_in' not in st.session_state or not st.session_state['logged_in']:
    st.warning("Por favor, inicia sesi√≥n para acceder a esta p√°gina.")
    st.stop()

# --- Configuraci√≥n y Constantes ---
st.set_page_config(page_title="Exploraci√≥n Rayos X", layout="wide")
st.markdown("# P√°gina 4: Exploraci√≥n del Dataset y Desbalance de Clases üìä")
st.sidebar.header("Exploraci√≥n Dataset")

# Definir rutas relativas al directorio principal de la app (donde est√° app.py)
BASE_DATA_PATH = "data/"
IMAGE_PATH = os.path.join(BASE_DATA_PATH, "images-small")
TRAIN_CSV_PATH = os.path.join(BASE_DATA_PATH, "train-small.csv")
VALID_CSV_PATH = os.path.join(BASE_DATA_PATH, "valid-small.csv")
TEST_CSV_PATH = os.path.join(BASE_DATA_PATH, "test.csv")

# Lista de columnas de etiquetas
LABEL_COLS = [
    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',
    'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule',
    'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'
]
IMAGE_COL = 'Image' # Columna con nombres de archivo
PATIENT_ID_COL = 'PatientId'
# --- Funciones Cacheadas ---

@st.cache_data # Cachear la carga de datos
def load_data(csv_path):
    """Carga el archivo CSV y realiza limpieza b√°sica."""
    try:
        df = pd.read_csv(csv_path)
        # Asegurar que las columnas de etiquetas existan y sean num√©ricas
        actual_labels = [col for col in LABEL_COLS if col in df.columns]
        for col in actual_labels:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
        # Crear columna FullPath
        if IMAGE_COL in df.columns:
             # Verificar si IMAGE_PATH existe antes de crear rutas completas
             if not os.path.isdir(IMAGE_PATH):
                  st.error(f"El directorio de im√°genes '{IMAGE_PATH}' no fue encontrado. Verifica la estructura de carpetas.")
                  # Devolver None o un df vac√≠o podr√≠a ser una opci√≥n, pero lanzar error es m√°s claro
                  raise FileNotFoundError(f"Directorio no encontrado: {IMAGE_PATH}")
             df['FullPath'] = df[IMAGE_COL].apply(lambda x: os.path.join(IMAGE_PATH, x))
        else:
             st.error(f"La columna '{IMAGE_COL}' no se encuentra en {os.path.basename(csv_path)}")
             df['FullPath'] = None # O manejar de otra forma

        return df, actual_labels
    except FileNotFoundError:
        st.error(f"Error: No se encontr√≥ el archivo CSV: {csv_path}")
        return None, []
    except Exception as e:
        st.error(f"Error al cargar o procesar {csv_path}: {e}")
        return None, []

@st.cache_data
def compute_class_freqs(labels_df, label_columns):
    """Calcula la frecuencia de casos positivos y negativos."""
    freqs = {}
    total_examples = len(labels_df)
    if total_examples == 0: return freqs
    for label in label_columns:
        pos_count = labels_df[label].sum()
        neg_count = total_examples - pos_count
        freqs[label] = (pos_count / total_examples, neg_count / total_examples)
    return freqs

@st.cache_data
def calculate_loss_weights(class_freqs):
    """Calcula los pesos w_pos y w_neg."""
    pos_weights = {}
    neg_weights = {}
    for label, (freq_pos, freq_neg) in class_freqs.items():
        pos_weights[label] = freq_neg
        neg_weights[label] = freq_pos
    return pos_weights, neg_weights

# --- Carga de Datos Principal (Entrenamiento) ---

st.header("1. Carga y Visi√≥n General de los Datos")
train_df, actual_label_cols = load_data(TRAIN_CSV_PATH)

if train_df is not None:
    st.success(f"Datos de entrenamiento cargados ({train_df.shape[0]} filas).")
    if st.checkbox("Mostrar datos crudos (primeras 100 filas)", False):
        st.dataframe(train_df.head(100))

    st.markdown(f"Columnas de patolog√≠as identificadas: `{', '.join(actual_label_cols)}`")

else:
    st.error("No se pudieron cargar los datos de entrenamiento. No se puede continuar con el an√°lisis.")
    st.stop() # Detener si no hay datos

# --- Carga de Datos Principal (Entrenamiento, Validaci√≥n, Prueba) ---
# Modificado para cargar los 3 datasets necesarios para el an√°lisis de superposici√≥n
st.header("1. Carga y Visi√≥n General de los Datos")
train_df, actual_label_cols = load_data(TRAIN_CSV_PATH)
valid_df, _ = load_data(VALID_CSV_PATH) # No necesitamos las etiquetas de validaci√≥n aqu√≠
test_df, _ = load_data(TEST_CSV_PATH)   # No necesitamos las etiquetas de prueba aqu√≠

data_loaded_successfully = True
if train_df is None:
    st.error("Fallo al cargar datos de entrenamiento.")
    data_loaded_successfully = False
if valid_df is None:
    st.error("Fallo al cargar datos de validaci√≥n.")
    data_loaded_successfully = False
if test_df is None:
    st.error("Fallo al cargar datos de prueba.")
    data_loaded_successfully = False

if data_loaded_successfully:
    st.success(f"Datos cargados: Entrenamiento ({train_df.shape[0]} filas), Validaci√≥n ({valid_df.shape[0]} filas), Prueba ({test_df.shape[0]} filas).")
    if st.checkbox("Mostrar datos crudos de entrenamiento (primeras 100 filas)", False):
        st.dataframe(train_df.head(100))
    st.markdown(f"Columnas de patolog√≠as identificadas: `{', '.join(actual_label_cols)}`")
else:
    st.error("No se pudieron cargar todos los conjuntos de datos necesarios. No se puede continuar con el an√°lisis completo.")
    st.stop()

# --- An√°lisis de Frecuencia de Etiquetas ---
st.header("2. An√°lisis del Desbalance de Clases")

class_frequencies = compute_class_freqs(train_df, actual_label_cols)

if not class_frequencies:
     st.warning("No se pudieron calcular las frecuencias de clase.")
else:
    # Preparar datos para gr√°ficos
    freq_data = []
    pos_freq_map = {}
    for label, (freq_pos, freq_neg) in class_frequencies.items():
        freq_data.append({'Patolog√≠a': label, 'Tipo': 'Positivo', 'Frecuencia': freq_pos})
        freq_data.append({'Patolog√≠a': label, 'Tipo': 'Negativo', 'Frecuencia': freq_neg})
        pos_freq_map[label] = freq_pos

    freq_df = pd.DataFrame(freq_data)
    # Ordenar por frecuencia positiva para visualizaci√≥n
    order = sorted(actual_label_cols, key=lambda l: pos_freq_map.get(l, 0), reverse=True)

    # Gr√°fico 1: Frecuencias Positivas vs Negativas
    st.subheader("Frecuencia de Casos Positivos vs. Negativos")
    fig1, ax1 = plt.subplots(figsize=(14, 6)) # Crear figura y ejes con Matplotlib
    sns.barplot(data=freq_df, x='Patolog√≠a', y='Frecuencia', hue='Tipo', order=order,
                palette={'Positivo': 'coral', 'Negativo': 'skyblue'}, ax=ax1)
    ax1.set_title('Frecuencia de Casos Positivos vs. Negativos por Patolog√≠a', fontsize=16)
    ax1.set_xlabel('Patolog√≠a', fontsize=12)
    ax1.set_ylabel('Frecuencia', fontsize=12)
    ax1.tick_params(axis='x', rotation=75)
    ax1.legend(title='Tipo de Caso')
    plt.tight_layout()
    st.pyplot(fig1) # Mostrar el gr√°fico de Matplotlib en Streamlit
    st.markdown("""
    **Observaci√≥n:** Se evidencia claramente el gran desbalance: la barra 'Negativo' (azul) es mucho m√°s alta que la 'Positivo' (coral) para casi todas las patolog√≠as. Las patolog√≠as m√°s comunes (ej. Infiltration) a√∫n son mucho menos frecuentes que la ausencia de la misma. Patolog√≠as como 'Hernia' son extremadamente raras en este conjunto.
    """)

    # --- C√°lculo y Visualizaci√≥n de Pesos ---
    st.header("3. P√©rdida Ponderada para Contrarrestar el Desbalance")
    st.markdown("""
    Para evitar que el modelo ignore las clases minoritarias (las patolog√≠as, que son las que nos interesan detectar), podemos usar una **funci√≥n de p√©rdida ponderada**. Asignamos un peso mayor a los errores en la clase minoritaria (positiva) y un peso menor a los errores en la clase mayoritaria (negativa).

    Calculamos los pesos como:
    * `Peso Positivo (w_pos) = Frecuencia Negativa`
    * `Peso Negativo (w_neg) = Frecuencia Positiva`
    """)

    pos_weights, neg_weights = calculate_loss_weights(class_frequencies)

    # Mostrar pesos en una tabla expandible
    with st.expander("Ver Pesos Calculados (w_pos, w_neg)"):
        weights_df = pd.DataFrame({
            'Patolog√≠a': actual_label_cols,
            'w_pos (freq_neg)': [pos_weights.get(l, 0) for l in actual_label_cols],
            'w_neg (freq_pos)': [neg_weights.get(l, 0) for l in actual_label_cols]
        }).set_index('Patolog√≠a')
        st.dataframe(weights_df.style.format("{:.4f}"))

    # Gr√°fico 2: Contribuci√≥n Ponderada Esperada
    st.subheader("Contribuci√≥n Esperada a la P√©rdida (Despu√©s de Ponderar)")
    weighted_contribution_data = []
    for label in actual_label_cols:
        freq_pos, freq_neg = class_frequencies.get(label, (0, 1))
        w_p = pos_weights.get(label, 0)
        w_n = neg_weights.get(label, 0)
        total_pos_contrib = freq_pos * w_p
        total_neg_contrib = freq_neg * w_n
        weighted_contribution_data.append({'Patolog√≠a': label, 'Tipo': 'Positivo Ponderado', 'Contribuci√≥n': total_pos_contrib})
        weighted_contribution_data.append({'Patolog√≠a': label, 'Tipo': 'Negativo Ponderado', 'Contribuci√≥n': total_neg_contrib})

    weighted_contrib_df = pd.DataFrame(weighted_contribution_data)

    fig2, ax2 = plt.subplots(figsize=(14, 6)) # Crear figura y ejes
    sns.barplot(data=weighted_contrib_df, x='Patolog√≠a', y='Contribuci√≥n', hue='Tipo', order=order,
                palette={'Positivo Ponderado': 'lightcoral', 'Negativo Ponderado': 'lightblue'}, ax=ax2)
    ax2.set_title('Contribuci√≥n Total Esperada a la P√©rdida (Ponderada)', fontsize=16)
    ax2.set_xlabel('Patolog√≠a', fontsize=12)
    ax2.set_ylabel('Contribuci√≥n Ponderada (freq * peso)', fontsize=12)
    ax2.tick_params(axis='x', rotation=75)
    ax2.legend(title='Tipo de Caso (Ponderado)')
    ax2.set_ylim(bottom=0) # Asegurar que el eje Y empiece en 0
    plt.tight_layout()
    st.pyplot(fig2) # Mostrar gr√°fico en Streamlit
    st.markdown("""
    **Observaci√≥n:** Despu√©s de aplicar la ponderaci√≥n, la contribuci√≥n total esperada de los casos positivos y negativos a la funci√≥n de p√©rdida se vuelve **igual** para cada patolog√≠a. Esto fuerza al modelo a prestar la misma atenci√≥n a acertar en casos positivos y negativos, independientemente de cu√°n rara sea la patolog√≠a.
    """)


# --- Exploraci√≥n de Im√°genes ---
st.header("4. Exploraci√≥n de Im√°genes de Ejemplo")
st.markdown("Selecciona un √≠ndice para ver la radiograf√≠a y sus etiquetas asociadas.")

if train_df is not None and 'FullPath' in train_df.columns and not train_df['FullPath'].isnull().all():
    # Slider para seleccionar √≠ndice de imagen
    max_index = len(train_df) - 1
    selected_index = st.slider("Selecciona √çndice de Imagen:", 0, max_index, random.randint(0, max_index))

    col1, col2 = st.columns([2, 1]) # Columna para imagen, columna para etiquetas

    with col1:
        image_path = train_df.loc[selected_index, 'FullPath']
        image_filename = train_df.loc[selected_index, IMAGE_COL]

        if image_path and os.path.exists(image_path):
            try:
                image = Image.open(image_path)
                st.image(image, caption=f"Imagen: {image_filename} (√çndice: {selected_index})", use_column_width=True)
            except Exception as e:
                st.error(f"No se pudo cargar la imagen {image_filename}: {e}")
        else:
            st.error(f"Ruta de imagen no encontrada o inv√°lida para el √≠ndice {selected_index}: {image_path}")

    with col2:
        st.subheader("Etiquetas Asociadas:")
        labels = train_df.loc[selected_index, actual_label_cols]
        positive_labels = labels[labels == 1].index.tolist()

        if positive_labels:
            for label in positive_labels:
                st.success(f"‚úì {label}") # Marca positiva
            # Mostrar tambi√©n las negativas podr√≠a ser √∫til
            negative_labels = labels[labels == 0].index.tolist()
            with st.expander("Ver etiquetas negativas"):
                 for label in negative_labels:
                      st.write(f"- {label}")

        else:
            st.info("No se encontraron patolog√≠as positivas para esta imagen (seg√∫n las etiquetas).")

        # Mostrar otras infos si existen
        other_cols = ['Patient Age', 'Patient Gender', 'View Position']
        for col in other_cols:
            if col in train_df.columns:
                st.write(f"**{col}:** {train_df.loc[selected_index, col]}")


else:
    st.warning("No se puede mostrar la exploraci√≥n de im√°genes porque la columna 'FullPath' falta o est√° vac√≠a, o las im√°genes no se encontraron.")


# --- Resumen Preprocesamiento ---
st.header("5. Resumen del Preprocesamiento (para el Modelo)")
st.markdown("""
Basado en la exploraci√≥n, los pasos clave para preparar estas im√°genes para un modelo CNN ser√≠an:

1.  **Carga en Escala de Grises:** Leer las im√°genes como monocrom√°ticas.
2.  **Redimensionamiento:** Cambiar el tama√±o a uno fijo (ej. 224x224 p√≠xeles).
3.  **Normalizaci√≥n:** Escalar los valores de p√≠xeles del rango [0, 255] al rango [0, 1].
4.  **Aumento de Datos (Solo Entrenamiento):** Aplicar transformaciones aleatorias (rotaciones, flips, zoom, etc.) a las im√°genes de entrenamiento para mejorar la robustez del modelo.

Estos pasos se implementar√≠an t√≠picamente usando generadores de datos como `ImageDataGenerator` de Keras o pipelines `tf.data`.
""")

# --- NUEVA SECCI√ìN: Histograma Interactivo ---
st.header("6. An√°lisis Interactivo de Intensidad de P√≠xeles")
st.markdown("El histograma muestra la distribuci√≥n de los valores de intensidad de los p√≠xeles (0=negro, 255=blanco) para la imagen seleccionada arriba con el slider.")

if train_df is not None and 'FullPath' in train_df.columns:
    # Reutilizar selected_index del slider anterior
    hist_image_path = train_df.loc[selected_index, 'FullPath']
    hist_image_filename = train_df.loc[selected_index, IMAGE_COL]

    if hist_image_path and os.path.exists(hist_image_path):
        try:
            hist_image = Image.open(hist_image_path).convert('L') # Cargar en escala de grises
            hist_image_array = np.array(hist_image)

            # Crear el histograma con Matplotlib
            fig_hist, ax_hist = plt.subplots(figsize=(10, 4))
            ax_hist.hist(hist_image_array.ravel(), bins=256, range=(0, 256), color='gray', alpha=0.8)
            ax_hist.set_title(f'Histograma de Intensidad de P√≠xeles (Imagen: {hist_image_filename})')
            ax_hist.set_xlabel('Intensidad de P√≠xel (0-255)')
            ax_hist.set_ylabel('Frecuencia (N√∫mero de P√≠xeles)')
            ax_hist.grid(axis='y', alpha=0.5)
            plt.tight_layout()
            st.pyplot(fig_hist) # Mostrar en Streamlit

        except Exception as e:
            st.error(f"No se pudo generar el histograma para la imagen {hist_image_filename}: {e}")
    else:
        st.warning(f"No se puede generar el histograma: Imagen no encontrada para el √≠ndice {selected_index}.")
else:
    st.warning("Carga los datos primero para ver el histograma.")


# --- NUEVA SECCI√ìN: Visor por Paciente ---
st.header("7. Visor de Im√°genes por Paciente")

if train_df is not None and PATIENT_ID_COL in train_df.columns:
    # Obtener lista √∫nica de IDs de paciente y ordenarla
    patient_ids = sorted(train_df[PATIENT_ID_COL].unique())

    # Permitir seleccionar un paciente
    selected_patient_id = st.selectbox("Selecciona un ID de Paciente:", options=patient_ids, index=0)

    if selected_patient_id:
        st.subheader(f"Radiograf√≠as para el Paciente ID: {selected_patient_id}")

        # Filtrar el dataframe por el paciente seleccionado
        patient_df = train_df[train_df[PATIENT_ID_COL] == selected_patient_id].reset_index() # Reset index para iterar f√°cil

        if not patient_df.empty:
            # Mostrar im√°genes en columnas (ej. 3 columnas)
            num_cols = 3
            cols = st.columns(num_cols)
            col_idx = 0

            for index, row in patient_df.iterrows():
                current_col = cols[col_idx % num_cols] # Ciclar entre columnas
                with current_col:
                    img_filename = row[IMAGE_COL]
                    img_path = row['FullPath']
                    st.markdown(f"**Imagen:** {img_filename}")

                    if img_path and os.path.exists(img_path):
                        try:
                            image = Image.open(img_path)
                            st.image(image, use_column_width=True)
                        except Exception as e:
                            st.error(f"Error al cargar {img_filename}: {e}", icon="‚ö†Ô∏è")
                    else:
                        st.warning(f"Imagen no encontrada: {img_filename}", icon="‚ö†Ô∏è")

                    # Mostrar etiquetas para esta imagen
                    st.markdown("**Etiquetas:**")
                    labels_patient = row[actual_label_cols]
                    positive_labels_patient = labels_patient[labels_patient == 1].index.tolist()
                    negative_labels_patient = labels_patient[labels_patient == 0].index.tolist()

                    if positive_labels_patient:
                        for label in positive_labels_patient:
                            st.success(f"‚úì {label}")
                    else:
                        st.info("Ninguna patolog√≠a positiva.")

                    # Expander opcional para negativas
                    with st.expander("Ver negativas"):
                         if negative_labels_patient:
                              st.markdown('\n'.join([f"- {label}" for label in negative_labels_patient]))
                         else:
                              st.write("Todas las etiquetas son positivas.")
                    st.markdown("---") # Separador entre im√°genes en la misma columna
                col_idx += 1 # Pasar a la siguiente columna (o volver a la primera)

        else:
            st.info(f"No se encontraron im√°genes para el paciente ID: {selected_patient_id}")
    else:
        st.info("Selecciona un ID de paciente de la lista.")

else:
    st.warning("No se puede mostrar el visor por paciente: Carga los datos primero y aseg√∫rate de que exista la columna 'Patient ID'.")

# --- NUEVA SECCI√ìN: An√°lisis de Superposici√≥n de Pacientes ---
st.header("8. An√°lisis de Superposici√≥n de Pacientes (Fuga de Datos)")
st.markdown("""
Es crucial verificar si los mismos pacientes aparecen en diferentes conjuntos de datos (entrenamiento, validaci√≥n, prueba). Si un paciente est√° en el conjunto de entrenamiento y tambi√©n en el de validaci√≥n/prueba, el modelo podr√≠a aprender caracter√≠sticas espec√≠ficas de ese paciente, llevando a una **evaluaci√≥n demasiado optimista** de su rendimiento (fuga de datos).
""")

# Verificar si todos los dataframes necesarios est√°n cargados
if data_loaded_successfully:
    # Extraer IDs √∫nicos (usar cache para esta operaci√≥n podr√≠a ser √∫til si los datasets son grandes)
    @st.cache_data
    def get_patient_ids(df, id_col):
        if id_col in df.columns:
            return set(df[id_col].astype(str).str.strip().unique())
        else:
            st.error(f"Columna '{id_col}' no encontrada en uno de los dataframes.")
            return set() # Devuelve conjunto vac√≠o si la columna no existe

    train_patient_ids = get_patient_ids(train_df, PATIENT_ID_COL)
    valid_patient_ids = get_patient_ids(valid_df, PATIENT_ID_COL)
    test_patient_ids = get_patient_ids(test_df, PATIENT_ID_COL)

    if train_patient_ids and valid_patient_ids and test_patient_ids: # Asegurarse que no est√©n vac√≠os
        # Calcular superposiciones
        overlap_train_valid = train_patient_ids.intersection(valid_patient_ids)
        overlap_train_test = train_patient_ids.intersection(test_patient_ids)
        overlap_valid_test = valid_patient_ids.intersection(test_patient_ids)
        n_overlap_tv = len(overlap_train_valid)
        n_overlap_tt = len(overlap_train_test)
        n_overlap_vt = len(overlap_valid_test)

        st.subheader("Resultados de la Superposici√≥n:")
        col_ov1, col_ov2, col_ov3 = st.columns(3)
        with col_ov1:
            st.metric("Entrenamiento ‚à© Validaci√≥n", f"{n_overlap_tv} Pacientes")
        with col_ov2:
            st.metric("Entrenamiento ‚à© Prueba", f"{n_overlap_tt} Pacientes")
        with col_ov3:
            st.metric("Validaci√≥n ‚à© Prueba", f"{n_overlap_vt} Pacientes")

        if n_overlap_tv > 0 or n_overlap_tt > 0 or n_overlap_vt > 0:
            st.warning("¬°Se detect√≥ superposici√≥n de pacientes! Esto puede causar fuga de datos.", icon="‚ö†Ô∏è")

            # Mostrar IDs superpuestos en expanders
            if n_overlap_tv > 0:
                with st.expander(f"Ver los {n_overlap_tv} IDs superpuestos (Entrenamiento ‚à© Validaci√≥n)"):
                    st.write(sorted(list(overlap_train_valid)))
            if n_overlap_tt > 0:
                with st.expander(f"Ver los {n_overlap_tt} IDs superpuestos (Entrenamiento ‚à© Prueba)"):
                    st.write(sorted(list(overlap_train_test)))
            if n_overlap_vt > 0:
                 with st.expander(f"Ver los {n_overlap_vt} IDs superpuestos (Validaci√≥n ‚à© Prueba)"):
                    st.write(sorted(list(overlap_valid_test)))

            # Explicar y mostrar el efecto de la limpieza
            st.subheader("Impacto de la Limpieza (Simulado)")
            st.markdown("""
            Para evitar la fuga de datos, los pacientes superpuestos deben eliminarse de los conjuntos de validaci√≥n y prueba antes de la evaluaci√≥n final. A continuaci√≥n se muestra cu√°ntos registros quedar√≠an:
            """)

            patients_to_remove_from_valid = list(overlap_train_valid.union(overlap_valid_test))
            patients_to_remove_from_test = list(overlap_train_test.union(overlap_valid_test))

            # Simular la limpieza (sin modificar los dataframes originales en la app)
            valid_df_cleaned_count = len(valid_df[~valid_df[PATIENT_ID_COL].astype(str).isin(patients_to_remove_from_valid)])
            test_df_cleaned_count = len(test_df[~test_df[PATIENT_ID_COL].astype(str).isin(patients_to_remove_from_test)])

            col_cln1, col_cln2 = st.columns(2)
            with col_cln1:
                st.metric("Registros Validaci√≥n (Original)", valid_df.shape[0])
                st.metric("Registros Validaci√≥n (Limpio)", valid_df_cleaned_count,
                          delta=f"{valid_df_cleaned_count - valid_df.shape[0]}", delta_color="inverse")
            with col_cln2:
                st.metric("Registros Prueba (Original)", test_df.shape[0])
                st.metric("Registros Prueba (Limpio)", test_df_cleaned_count,
                          delta=f"{test_df_cleaned_count - test_df.shape[0]}", delta_color="inverse")

            if valid_df_cleaned_count < 20 or test_df_cleaned_count < 20: # Umbral arbitrario
                 st.error("ADVERTENCIA: Despu√©s de la limpieza, uno o ambos conjuntos de validaci√≥n/prueba quedar√≠an muy peque√±os, lo que har√≠a la evaluaci√≥n poco fiable. Esto sugiere que la divisi√≥n inicial de datos deber√≠a hacerse a nivel de paciente.", icon="üö®")

        else:
            st.success("¬°No se detect√≥ superposici√≥n de pacientes entre los conjuntos! Los conjuntos parecen estar correctamente separados a nivel de paciente.", icon="‚úÖ")

    else:
         st.warning("No se pudieron extraer los IDs de paciente de todos los dataframes.")

else:
    st.warning("Carga todos los conjuntos de datos (entrenamiento, validaci√≥n, prueba) para realizar el an√°lisis de superposici√≥n.")

st.markdown("---") # Separador final de p√°gina
